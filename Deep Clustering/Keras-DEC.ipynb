{"nbformat":4,"nbformat_minor":0,"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.6.8"},"colab":{"name":"Keras-DEC.ipynb","provenance":[],"private_outputs":true,"collapsed_sections":[],"toc_visible":true},"accelerator":"GPU"},"cells":[{"cell_type":"code","metadata":{"id":"Nc7JCAChPNOM","colab_type":"code","colab":{}},"source":["from google.colab import drive\n","drive.mount('/content/drive')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"S_YTzw6o_1pq","colab_type":"code","colab":{}},"source":["from time import time\n","import numpy as np\n","import cv2\n","import os\n","import h5py\n","import keras.backend as K\n","from keras.engine.topology import Layer, InputSpec\n","from keras.layers import Dense, Input, Conv2D, Flatten, Reshape\n","from keras.layers import LeakyReLU, Conv2DTranspose\n","from keras.models import Model, load_model\n","from keras.optimizers import SGD\n","from keras import callbacks\n","from keras.initializers import VarianceScaling\n","from sklearn.cluster import KMeans\n","from keras.preprocessing.image import ImageDataGenerator\n","#import metrics\n","\n"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"LYWQsn9qMfNM","colab_type":"code","colab":{}},"source":["def csv_image_generator(inputPath, bs):\n","  \n","  f = open(inputPath, \"r\")\n","  \n","  while True:\n","    \n","    image = []\n","    while len(image) < bs:\n","      line = f.readline()\n","      if line == \"\":\n","        f.seek(0)\n","        line = f.readline()\n","        \n","      line = line.strip().split(\",\")\n","      \n","      img = cv2.imread(line[0])\n","      img = cv2.resize(img, (64,64))\n","      image.append(img/255)\n","      \n","      if len(image) == bs:\n","        yield (np.array(image),np.array(image))\n","        image = []"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"gbBMqqUFd6gi","colab_type":"code","colab":{}},"source":["def generator(images, dir, bs=6):\n","    while True:\n","        num_batches = int(len(images)/bs)\n","        start = bs\n","        for i in range(num_batches):\n","            x = []\n","            start = i*bs\n","            end = start + bs\n","\n","            for img in images[start:end]:\n","                img = cv2.imread(os.path.join(dir, img))\n","                #img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB)\n","                img = cv2.resize(img, (64,64))\n","                x.append(img/255.)\n","\n","            yield (np.array(x), np.array(x))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Ebx1VQ2l_1pv","colab_type":"code","colab":{}},"source":["def autoencoderConv2D(input_shape=(64, 64, 3), filters=[32, 64, 128, 10]):\n","    input_img = Input(shape=input_shape)\n","    if input_shape[0] % 8 == 0:\n","        pad3 = 'same'\n","    else:\n","        pad3 = 'valid'\n","    x = Conv2D(filters[0], 5, strides=2, padding='same', activation='relu', name='conv1', input_shape=input_shape)(input_img)\n","\n","    x = Conv2D(filters[1], 5, strides=2, padding='same', activation='relu', name='conv2')(x)\n","\n","    x = Conv2D(filters[2], 3, strides=2, padding=pad3, activation='relu', name='conv3')(x)\n","\n","    x = Flatten()(x)\n","    encoded = Dense(units=filters[3], name='embedding', activation='relu')(x)\n","    x = Dense(units=filters[2]*int(input_shape[0]/8)*int(input_shape[0]/8), activation='relu')(encoded)\n","\n","    x = Reshape((int(input_shape[0]/8), int(input_shape[0]/8), filters[2]))(x)\n","    x = Conv2DTranspose(filters[1], 3, strides=2, padding=pad3, activation='relu', name='deconv3')(x)\n","\n","    x = Conv2DTranspose(filters[0], 5, strides=2, padding='same', activation='relu', name='deconv2')(x)\n","\n","    decoded = Conv2DTranspose(input_shape[2], 5, strides=2, padding='same', activation='relu', name='deconv1')(x)\n","    return Model(inputs=input_img, outputs=decoded, name='AE'), Model(inputs=input_img, outputs=encoded, name='encoder')"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"3UeC6j7q_1qH","colab_type":"text"},"source":["## Hyper-params"]},{"cell_type":"code","metadata":{"id":"y9eU5nBw_1qI","colab_type":"code","colab":{}},"source":["dims = [32, 64, 128, 10]\n","init = VarianceScaling(scale=1. / 3., mode='fan_in',\n","                           distribution='uniform')\n","pretrain_optimizer = SGD(lr=0.1, momentum=0.9)\n","pretrain_epochs = 30\n","batch_size = 6\n","save_dir = ''"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"VjAAg_jY3sS6","colab_type":"code","colab":{}},"source":["dir = r'drive/My Drive/Deep_Clustering/person_rcnn/'\n","images = os.listdir(dir)\n","trainGen = csv_image_generator(r'drive/My Drive/Deep_Clustering/trainData.csv', bs=batch_size)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"yRl29Ib9Vu-P","colab_type":"code","colab":{}},"source":["autoencoder, encoder = autoencoderConv2D((64,64,3), dims)\n","autoencoder.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"Z527zGug_1qd","colab_type":"text"},"source":["## Pretrain auto-encoder"]},{"cell_type":"code","metadata":{"scrolled":true,"id":"dJ7QAeBN_1qe","colab_type":"code","colab":{}},"source":["autoencoder.compile(optimizer=pretrain_optimizer, loss='mse')\n","autoencoder.fit_generator(trainGen, steps_per_epoch=1613, epochs=20, initial_epoch=0, shuffle=True) #, callbacks=cb)\n","autoencoder.save(save_dir + 'ae_model.h5')"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"pQAxoUSh1DXJ","colab_type":"code","colab":{}},"source":["autoencoder = load_model('ae_model.h5')\n","encoder = Model(autoencoder.input, autoencoder.layers[5].output)\n","#res = encoder.predict_generator(trainGen, steps=1613, verbose = 0)\n","encoder.summary()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"Lvn9B5Hs0eN4","colab_type":"code","colab":{}},"source":["h5f = h5py.File('PredData.h5', 'w')\n","h5f.create_dataset('dataset_1',data = pred,  dtype=\"float32\")\n","h5f.close()"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"durUveEpzHgh","colab_type":"code","colab":{}},"source":["h5f = h5py.File('PredData.h5', 'r')\n","for key in h5f.keys():\n","  print(key)\n","pred = h5f['dataset_1']"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"2tf2ur6xDsYa","colab_type":"code","colab":{}},"source":["import scipy.cluster.hierarchy as shc\n","import pandas as pd\n","import matplotlib.pyplot as plt\n","%matplotlib inline\n","\n","from sklearn.preprocessing import normalize\n","\n","df = pd.DataFrame({'C1':pred[:,0], 'C2':pred[:,1], 'C3':pred[:,2], 'C4':pred[:,3], 'C5':pred[:,4], 'C6':pred[:,5],\n","                  'C7':pred[:,6], 'C8':pred[:,7], 'C9':pred[:,8], 'C10':pred[:,9],})\n","\n","data = normalize(df)\n","data = pd.DataFrame(data, columns=df.columns)\n","print(data.head())\n","plt.figure(figsize=(10,7))  \n","plt.title(\"Dendrograms\")  \n","dend = shc.dendrogram(shc.linkage(df, method='ward'))"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"561zCzVr8DlH","colab_type":"code","colab":{}},"source":["from sklearn.cluster import AgglomerativeClustering\n","cluster = AgglomerativeClustering(n_clusters=500, affinity='euclidean', linkage='ward')  \n","res = cluster.fit_predict(data)"],"execution_count":0,"outputs":[]},{"cell_type":"code","metadata":{"id":"eI5eHR1w-cgV","colab_type":"code","colab":{}},"source":["plt.figure(figsize=(10, 7))  \n","plt.scatter(data['C1'], data['C2'], c=cluster.labels_)"],"execution_count":0,"outputs":[]}]}